\section{Reference Implementations}\label{section:implementations}

\subsection{Requirements}
    Reference implementations were selected to maximize the following selection criteria:
    \begin{enumerate}
        \itemsep0em
        \item Relevance to intelligence and security,
        \item Is or was SOTA,
        \item Intrinsic telemetry,
        \item Cross-architecture availability,
        \item Ease of integration, and
        \item Community acceptance and support.
    \end{enumerate}
    
\subsection{Problem Domains}
    Two problem sets, community detection and subgraph matching are the chosen graph problems relevant to the I\&S domain. 
    Both are NP-Complete problems with real-world applications, and so balance the complexity and utility for a useful benchmark.    

    \subsubsection{Community Detection}
        The Community Detection problem asks: given a graph, are there elements of that graph more tightly connected than other parts? 
        The goal is to uncover the inherent organizational structure or modular patterns within complex systems such as social networks, biological networks, or information networks. 
        In a real-world setting, a military force undertaking peacekeeping might want to understand the population demographics of a region. 
        They could analyze to determine what the local cliques, tribes, or groups are and then determine how those groups interact with each other, which are likely to be friendly and which are likely to be hostile.

    \subsubsection{Subgraph Matching}
        In terms of a graph, subgraph matching asks, given a query graph and a target graph, are there any instances of that query graph contained within the target graph? 
        In this context, the pattern graph represents a specific structure or motif that the algorithm seeks to identify within the larger graph. 
        The goal is to locate all instances where the pattern occurs as a connected subgraph in the target graph. 
        In a real-world context, we might know that a precursor to a terrorist attack is for a cell member to visit three different hardware stores and buy a particular item at each one. 
        Knowing the pattern, we could monitor credit card transactions to observe if any single credit card makes that purchasing pattern and flag it for investigation. 
        Efficiently solving the subgraph matching problem is computationally challenging, especially for large graphs, and various algorithms and heuristics are employed to address this problem in different application domains. 

\subsection{Reference Implementations}\label{subsection:reference_implementations}

Ideally, a single code base will be recompiled to automatically optimize for each hardware architecture -- the GraphBLAS suite offers this layer of abstraction as it reaches maturity and porting the implementations to GraphBLAS is important future work. 

Currently, the AGHAB uses widely accepted parallel implementations specific to each architecture (CPU, GPU, etc), aiming to identify where the same algorithm is optimized to run on different hardware, rather than forcing all hardware to run the same code.
The serial performance is derived by running the parallel implementation with a single worker node.

The AGHAB Experiment Framework abstracts away the operation of each implementation. 
Instead, an experimenter specifies the number of workers, the datasets to use, the metrics to generate and the implementations to run, and the experiment framework checks the compilation status, routes the instructions and collects the results.

\subsubsection{Community Detection -- The Louvain Algorithm}

The Louvain algorithm is a widely used heuristic approach for community detection with numerous implementations available~\cite{Blondel2008}. 
It optimizes modularity, a metric that quantifies the quality of community assignments based on the density of connections within communities compared to those between communities~\cite{Newman2004a}. 
The Vite~\cite{Ghosh2018,Ghosh2018a,Ghosh2019} (CPU) and Gunrock~\cite{Wang2016} (GPU) implement The Louvain algorithm in AGHAB, with minor changes.

    \underline{\textbf{Vite}}
        Vite is a Message Passing Interface (MPI)+Open Multi-Processing (OpenMP) distributed memory parallel implementation of the Louvain method for community detection developed by Washington State University and the Pacific Northwest National Laboratory\footnote{\url{https://github.com/ECP-ExaGraph/vite}}.
        We only use it on a single node, to emulate shared memory parallelism.
        It accepts input graphs in most of the common formats, converting them into a binary format that the Vite Louvain implementation uses.        

    \underline{\textbf{Gunrock Louvain}}
        Gunrock is a specialized graph-processing library designed for GPU acceleration created by the University of California at Davis for the HIVE program~\cite{Wang2016}. 
        % Gunrock's performance has been extensively evaluated across various GPU architectures and graph primitives, including traversal-based and ranking algorithms, as well as triangle counting and bipartite-graph-based algorithms. 
        % Gunrock is tailored for parallel GPU architectures, making it well-suited for handling large-scale networks efficiently and measuring performance across the GPU. 
        % Gunrock`s data-centric programming model is targeted at GPUs and offers advantages over other programming models. 
        % Gunrock`s programming model is a better fit to high-performance GPU implementations than traditional programming models adapted from CPUs. 
        % It is important to note that Gunrock does no preprocessing on its datasets and that its default parameters run the simplest possible configurations.
        We use the Gunrock implementation of the Louvain algorithm from the dev branch of version $1.2$ of the Gunrock library\footnote{\url{https://github.com/gunrock/gunrock/tree/dev/examples/louvain}}. It was not part of the stable release, so the AGHAB version has minor modifications to support compilation and execution. 
        The Gunrock library expects the Matrix Market Graph Format (MTX) as input, and graphs stored in other formats are converted to MTX before processing.  
        % To run the implementation the following parameterized information is needed: input graph file name, path to the file, number of threads. 
        % For testing, we ran Gunrock on an NVIDIA Tesla GPU using a remote Amazon EC2 server. 
        The process of cloning the original Gunrock repository, compiling it, gathering data input, running the algorithm, and extracting metrics has been automated and abstracted using the benchmarking framework.

\subsubsection{Subgraph Matching -- The VF3 Algorithm}
    The VF3~\cite{Carletti2017} and VF3P~\cite{Carletti2019} algorithms are among the leading heuristic approaches to Subgraph Matching currently available for CPU. 
    The GPU implementation uses a custom algorithm, Gunrock Subgraph Matching (GSM)~\cite{Wang2016}, to better leverage the capabilities of a GPU, but we note is inspired by VF3.

    \underline{\textbf{VF3LIB}}
        vf3lib is a software library created by Mivia Lab containing all the currently published versions of VF3, an algorithm to solve subgraph isomorphism\footnote{\url{https://github.com/MiviaLab/vf3lib}}. 
        % The effectiveness of VF3 has been experimentally validated using several publicly available datasets, showing a significant speedup concerning its predecessor and to the other most advanced state-of-the-art algorithms. 
        % VF3 has the ability to maintain a low memory requirement as its predecessor as well as faster than VF2. VF3 has been tested on the MIVIA large dense graphs dataset, composed of dense graphs whose size ranges from 300 to 10,000 nodes. 
        This library contains both serial and parallel implementations that can be run on the CPU. 
        Both versions require input graph files in a binary format that input graphs must be converted to before processing.

    \underline{\textbf{Gunrock Subgraph Matching}}
        GSM is BFS-based, allowing it to leverage the parallel processing capabilities of the GPU.
        We use the implementation from the dev branch of version $1.2$ of Gunrock\footnote{\url{https://github.com/gunrock/gunrock/tree/dev/examples/sm}} in AGHAB 
        % Using the standard DFS approach is difficult to parallelize because it is recursive and needs extra scheduling in order to make use of many parallel cores, making it a non GPU-friendly approach. 
        GSM borrows ideas from VF3, specifically during preprocessing when precomputing the query nodes` order based on the Maximum Likelihood Estimation (MLE) method. 
        % GSM was therefore a suitable choice to use as a reference implementation given its convenience as an already established tool part of the Gunrock library and its relevance and efficiency as a subgraph matching algorithm. 
        % A similar approach to the Gunrock Louvain implementation was repeated here to benchmark test datasets on the GPU. 
    